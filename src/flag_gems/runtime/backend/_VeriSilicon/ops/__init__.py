from backend_utils import Autograd

from . import add


def get_specific_ops():
    return ()


def get_unused_ops():
    return ("addmm",
            "all",
            "bitwise_and.Tensor",
            "bitwise_and.Scalar",
            "bitwise_and.Scalar_Tensor",
            "bitwise_not",
            "bitwise_or.Tensor",
            "bitwise_or.Scalar",
            "bitwise_or.Scalar_Tensor",
            "bmm",
            "cat",
            "pad",
            "constant_pad_nd",
            "cummin",
            "div.Tensor_mode",
            "div.Scalar_mode",
            "divide.Tensor_mode",
            "divide.Scalar_mode",
            "floor_divide",
            "floor_divide.Scalar",
            "native_dropout",
            "embedding",
            "eq.Tensor",
            "eq.Scalar",
            "exponential_",
            "ge.Tensor",
            "ge.Scalar",
            "gelu",
            "native_group_norm",
            "_weight_norm_interface",
            "_weight_norm",
            "gt.Tensor",
            "gt.Scalar",
            "instance_norm",
            "isfinite",
            "isin.Tensor_Tensor",
            "isin.Scalar_Tensor",
            "isin.Tensor_Scalar",
            "isinf",
            "isnan",
            "minimum",
            "maximum",
            "native_layer_norm",
            "le.Tensor",
            "le.Scalar",
            "lt.Tensor",
            "lt.Scalar",
            "rand",
            "randn",
            "rand_like",
            "randn_like",
            "resolve_neg",
            "normal.Tensor_float",
            "normal.float_Tensor",
            "normal.Tensor_Tensor",
            "uniform_",
            "mm",
            "multinomial",
            "mv",
            "ne.Tensor",
            "ne.Scalar",
            "pow.Scalar",
            "pow.Tensor_Scalar",
            "pow.Tensor_Tensor",
            "reciprocal",
            "relu",
            "rsqrt",
            "sigmoid",
            "silu",
            "softmax.int",
            "sort",
            "triu",
            "topk",
            "var_mean.correction",
            "linalg_vector_norm",
            "where.self_out",
            "where.self",
            "where.ScalarSelf",
            "where.ScalarOther",
            "max",
            "max.dim",
            "min",
            "min.dim",
            "amax",
            "argmax",
            "prod",
            "prod.dim_int",
            "scaled_dot_product_attention",
            "all",
            "all.dim",
            "all.dims",
            "any",
            "any.dim",
            "any.dims",
            "log_softmax.int",
            "outer",
            "cross_entropy_loss",
            "scatter.src",
            "scatter.reduce",
            "gather",
            "isclose",
            "allclose",
            "flip",
            "slice_scatter",
            "select_scatter",
            "index_select",
            "tile",
            "masked_fill.Tensor",
            "masked_fill.Scalar",
            "masked_fill_.Tensor",
            "masked_fill_.Scalar",
            "_unique2",
            "_upsample_bicubic2d_aa",
            "upsample_nearest2d",
            "nonzero",
            "repeat",
            "masked_select",
            "hstack",
            "stack",
            "cat",
            "vstack",
            "repeat_interleave.Tensor",
            "randperm",
            "diag",
            "diag_embed",
            "diagonal_backward",
            "index_add",
            "count_nonzero",
            "logical_or",
            "logical_and",
            "logical_not",
            "tanh")


__all__ = ["get_specific_ops", "get_unused_ops"]
